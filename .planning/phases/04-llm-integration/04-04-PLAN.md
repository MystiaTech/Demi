---
phase: 04-llm-integration
plan: 04
type: execute
wave: 3
depends_on: ["04-01", "04-02", "04-03"]
files_modified:
  - src/llm/codebase_reader.py
  - src/llm/inference.py
  - src/conductor/orchestrator.py
  - tests/test_llm_integration.py
autonomous: true
must_haves:
  truths:
    - "Demi can read her own source code (Python files in src/ directory)"
    - "Code snippets are injected into prompts for self-aware responses"
    - "AUTO-01 requirement met: Demi understands her own architecture"
    - "End-to-end message → inference → response working through Conductor"
  artifacts:
    - path: "src/llm/codebase_reader.py"
      provides: "CodebaseReader class that loads and caches Demi's source code"
      exports: ["CodebaseReader", "CodeSnippet"]
    - path: "src/llm/inference.py"
      provides: "Updated with codebase context injection"
      exports: ["OllamaInference"]
  key_links:
    - from: "src/llm/codebase_reader.py"
      to: "src/"
      via: "Read and cache Python source files"
      pattern: "glob|walk|read_file"
    - from: "src/llm/codebase_reader.py"
      to: "src/llm/prompt_builder.py"
      via: "Inject relevant code snippets into system prompt"
      pattern: "relevant_code|inject|context"
---

<objective>
Implement AUTO-01 self-awareness: Demi can read and understand her own codebase. This completes the LLM integration phase and enables future self-modification features.

Purpose: Demi must have introspective capability - understanding her own emotional system, inference pipeline, and decision-making code. This makes her responses about her own architecture authentic, and enables reasoning about self-improvement.

Output: CodebaseReader that loads Demi's source code, CodeSnippet abstraction for injecting relevant code into prompts, full end-to-end inference pipeline with self-awareness.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@.planning/phases/04-llm-integration/04-DISCOVERY.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/PROJECT.md
@src/llm/inference.py
@src/llm/prompt_builder.py
@src/conductor/orchestrator.py
@src/models/emotional_state.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create CodebaseReader with semantic code retrieval</name>
  <files>src/llm/codebase_reader.py</files>
  <action>
Create `src/llm/codebase_reader.py` with:

**CodeSnippet dataclass:**
```python
@dataclass
class CodeSnippet:
    file_path: str  # Relative path (e.g., "src/models/emotional_state.py")
    class_or_function: str  # Name of class/function (e.g., "EmotionalState")
    start_line: int
    end_line: int
    content: str  # The actual code
    tokens: int  # Token count of this snippet
    relevance_score: float = 0.0  # For ranking (0-1)
```

**Class CodebaseReader:**
- Constructor: `__init__(logger: DemiLogger, codebase_root: str = "src/", token_counter: Callable[[str], int])`
  - Load all Python files in codebase_root on initialization
  - Cache in memory: {file_path: full_file_content}
  - Parse class/function definitions for semantic retrieval
  - Log: "Loaded codebase: {N} files, {X} classes/functions"

- Method: `get_architecture_overview() -> str`
  - Return high-level summary of Demi's architecture:
    ```
    DEMI ARCHITECTURE OVERVIEW
    
    Core Components:
    - Emotional System (src/models/emotional_state.py): EmotionalState tracks 9 emotions
    - Personality Modulation (src/conductor/personality_modulator.py): Adjusts response tone
    - LLM Inference (src/llm/inference.py): Ollama integration via llama3.2:1b
    - Conductor Orchestrator (src/conductor/orchestrator.py): Manages all integrations
    
    Workflow:
    1. Receive message from platform
    2. Load emotional state from database
    3. Modulate personality based on emotions
    4. Build prompt with emotional context
    5. Call Ollama for inference
    6. Process response, clean text
    7. Update emotional state
    8. Send response back to user
    ```
  - Keep under 500 tokens (summary, not full files)

- Method: `get_relevant_code(query: str, max_results: int = 3) -> list[CodeSnippet]`
  - Input: natural language query (e.g., "how do emotions work?")
  - Semantic retrieval: find relevant code sections
  - Approach (simple): keyword matching on class/function names + docstrings
    - Extract keywords from query
    - Search through loaded files for matching class/function names
    - Return top N by relevance score
  - Examples:
    - Query "emotions" → [EmotionalState, DecaySystem, InteractionHandler]
    - Query "personality" → [PersonalityModulator, ModulationParameters]
    - Query "inference" → [OllamaInference, PromptBuilder]
  - Return list of CodeSnippet objects (up to N)
  - Log: "Retrieved {N} code snippets for query: {query}"

- Method: `get_code_for_module(module_name: str) -> Optional[CodeSnippet]`
  - Input: class or function name (e.g., "EmotionalState")
  - Find and return full class definition (from `class Name` to next top-level def/class)
  - Return CodeSnippet with full content
  - Return None if not found

- Private method: `_extract_code_blocks() -> dict[str, list[CodeSnippet]]`
  - Parse all loaded files
  - Extract class and function definitions with line numbers
  - Build index: {class_name: CodeSnippet, function_name: CodeSnippet}
  - Cache results for fast retrieval

- Private method: `_calculate_relevance(query_keywords: list[str], snippet: CodeSnippet) -> float`
  - Simple scoring: how many query keywords appear in code?
  - Score = (keyword_matches / len(keywords)) * (1 - (len(snippet) / max_snippet_length))
  - Prefer shorter, more targeted snippets
  - Return float 0-1

**Test cases:**
- `test_load_codebase()` - verify files loaded, count correct
- `test_architecture_overview()` - overview string contains expected components
- `test_get_relevant_code_emotions()` - query "emotions" returns emotional system code
- `test_get_relevant_code_personality()` - query "personality" returns personality modulator
- `test_get_code_for_module()` - retrieve full EmotionalState class
  </action>
  <verify>
1. `from src.llm.codebase_reader import CodebaseReader, CodeSnippet` succeeds
2. Initialize CodebaseReader:
   - Logs "Loaded codebase: X files" (should be ~15-20 Python files)
   - No errors loading files
3. Get architecture overview:
   - Returns string containing "Emotional System", "Personality Modulation", "LLM Inference"
   - String length < 500 tokens
4. Retrieve code:
   - Query "emotions" returns list containing EmotionalState, DecaySystem, or similar
   - Query "personality" returns PersonalityModulator
   - Query "inference" returns OllamaInference
5. Get module code:
   - `get_code_for_module("EmotionalState")` returns CodeSnippet with full class definition
   - CodeSnippet.content starts with "class EmotionalState"
  </verify>
  <done>
CodebaseReader loads Demi's source code, provides semantic retrieval of relevant code snippets, and enables self-awareness. Ready to integrate into prompts.
  </done>
</task>

<task type="auto">
  <name>Task 2: Inject codebase context into prompts and implement full end-to-end inference</name>
  <files>src/llm/prompt_builder.py, src/llm/inference.py, src/conductor/orchestrator.py</files>
  <action>
Update prompt building and Conductor to include code context:

**Update PromptBuilder (src/llm/prompt_builder.py):**
- Add to constructor: `codebase_reader: Optional[CodebaseReader] = None`
- Modify `build()` method:
  - If codebase_reader provided:
    1. Get architecture overview: `overview = codebase_reader.get_architecture_overview()`
    2. Extract query from latest user message (last message in history)
    3. Get relevant code: `relevant_code = codebase_reader.get_relevant_code(query, max_results=2)`
    4. Inject into system prompt:
       ```
       [BASE_DEMI_PROMPT + emotional modulation]
       
       MY ARCHITECTURE:
       {overview}
       
       [If code is relevant to current conversation:]
       RELEVANT CODE (For your reference):
       {code_snippet_1}
       
       {code_snippet_2}
       ```
    5. Keep total system prompt under 2000 tokens (system + code)
    - If codebase_reader not provided, proceed as before (no code injection)
  - Log: "Injected architecture overview and {N} code snippets"

**Update OllamaInference (src/llm/inference.py):**
- Add to constructor: `codebase_reader: Optional[CodebaseReader] = None`
- Pass to PromptBuilder during initialization

**Update Conductor (src/conductor/orchestrator.py):**
- Instantiate CodebaseReader in startup:
  ```python
  self.codebase_reader = CodebaseReader(logger=self.logger)
  self.prompt_builder = PromptBuilder(
      logger=self.logger,
      token_counter=self.llm._count_tokens,
      codebase_reader=self.codebase_reader
  )
  ```
- Wire into full inference pipeline:
  ```python
  async def handle_message(user_message: str, platform_id: str):
      # 1. Load emotional state
      emotional_state = self.emotion_persistence.load(platform_id)
      
      # 2. Add user message to history
      self.conversation_history.add_message("user", user_message, emotional_state)
      
      # 3. Get modulation
      modulation = self.personality_modulator.modulate(emotional_state)
      
      # 4. Build prompt (with code context)
      messages = self.prompt_builder.build(
          emotional_state, 
          modulation, 
          self.conversation_history.trim_for_inference(...)
      )
      
      # 5. Call LLM
      response = await self.llm.chat(messages)
      
      # 6. Process response
      processed = self.response_processor.process_response(response, ...)
      
      # 7. Save response to history
      self.conversation_history.add_message("assistant", processed.text, processed.emotional_state_after)
      
      # 8. Return to user
      return processed.text
  ```

**Create full integration test (tests/test_llm_full_integration.py):**
- `test_full_inference_pipeline_with_codebase_awareness()`
  - Create mock emotional state
  - Create user message: "How do you work?"
  - Run through full pipeline
  - Verify: response mentions emotional system or architecture (proves code was accessible)
  - Verify: response is personality-consistent (proves modulation working)
  - Verify: response < 3 seconds (proves latency acceptable)
- `test_message_without_code_relevance()`
  - Query: "Hey, how are you?"
  - Code snippets should be minimal or architecture overview only
  - Verify: response doesn't randomly mention code
- `test_full_conversation_history_management()`
  - Send 5 messages in sequence
  - Verify: history accumulates, trimming works if approaching limit
  - Verify: conversation context maintained (no random message loss)
  </action>
  <verify>
1. Prompt builder accepts codebase_reader
2. Build prompt with user message about emotions/architecture:
   - System prompt includes architecture overview
   - Relevant code snippets injected
   - Total tokens < 2000
3. Full pipeline test:
   - Message → emotional state → modulation → prompt (with code) → inference → response processing
   - All steps complete without errors
   - Response text meaningful (no corruption)
4. Codebase context affects responses:
   - Question about emotions → response references emotional system
   - Question about how Demi works → response mentions architecture
5. Integration tests pass: `pytest tests/test_llm_full_integration.py -v`
6. Latency maintained <3 seconds with code context
  </verify>
  <done>
Full end-to-end inference pipeline implemented with codebase self-awareness. Code context injected into prompts. AUTO-01 requirement met: Demi can read and reference her own code. All components integrated through Conductor.
  </done>
</task>

</tasks>

<verification>
After all tasks:
1. CodebaseReader loads all source files
2. Architecture overview accessible
3. Code snippets retrieved semantically (emotions → emotional system code)
4. Prompts inject architecture + relevant code snippets
5. Full end-to-end pipeline working: message → emotional state → modulation → prompt (with code) → inference → response → logging → emotional update
6. Latency < 3 seconds p90 with code context
7. All tests passing: `pytest tests/test_llm_codebase.py tests/test_llm_full_integration.py -v`
8. Logs show code retrieval and injection operations
9. AUTO-01 requirement complete: Demi reads own code and references it in responses
</verification>

<success_criteria>
- CodebaseReader loads Demi's source code (15-20 Python files)
- Semantic code retrieval working (query "emotions" finds emotional system code)
- Architecture overview generated (high-level summary <500 tokens)
- Code snippets injected into prompts (up to 2 relevant snippets per inference)
- Full end-to-end inference pipeline: message → emotion → modulation → prompt (+ code) → inference → response → update
- AUTO-01 requirement satisfied: Demi understands her own architecture and can reference code
- Responses incorporate codebase awareness (mentions architecture when relevant)
- Latency maintained <3 seconds p90
- All integration tests passing
- Phase 04 complete and ready for Phase 05 (Discord integration)
</success_criteria>

<output>
Create `.planning/phases/04-llm-integration/04-04-SUMMARY.md` with:
- CodebaseReader implemented, loads Demi's source code
- Semantic code retrieval working, architecture overview generated
- Code snippets injected into prompts (auto-selected based on query relevance)
- Full end-to-end inference pipeline complete and integrated with Conductor
- AUTO-01 self-awareness requirement met: Demi reads own code
- Responses incorporate codebase context (mentions architecture, emotion system, etc.)
- Latency baseline <3sec p90, all tests passing
- Phase 04 COMPLETE: LLM integration ready for platform integration (Phase 05-06)
</output>
