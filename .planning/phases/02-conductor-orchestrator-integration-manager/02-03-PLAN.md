---
phase: 02-conductor-orchestrator-integration-manager
plan: 03
type: execute
wave: 2
depends_on: [02-01]
files_modified: [src/conductor/scaler.py, src/conductor/resource_monitor.py]
autonomous: true
must_haves:
  truths:
    - "Resource monitor tracks RAM/CPU usage with 30-second sliding window analysis"
    - "Predictive scaler uses Linear Regression to forecast resource needs"
    - "Auto-scaling disables integrations at 80% RAM and re-enables at 65%"
    - "Scaling decisions use ML predictions with smoothing to prevent oscillation"
  artifacts:
    - path: "src/conductor/resource_monitor.py"
      provides: "System resource monitoring with historical tracking"
      contains: "class ResourceMonitor"
      min_lines: 50
    - path: "src/conductor/scaler.py"
      provides: "Predictive auto-scaling with ML models"
      contains: "class PredictiveScaler"
      min_lines: 70
  key_links:
    - from: "src/conductor/scaler.py"
      to: "src/conductor/resource_monitor.py"
      via: "resource metrics feeding ML prediction models"
      pattern: "resource_metrics\\.get_history"
    - from: "src/conductor/scaler.py"
      to: "src/plugins/manager.py"
      via: "scaling decisions affecting plugin availability"
      pattern: "plugin_manager\\.disable_plugin"
    - from: "src/conductor/resource_monitor.py"
      to: "src/conductor/metrics.py"
      via: "resource metrics recording"
      pattern: "system_resources\\.set"
---

<objective>
Build the resource monitoring and predictive auto-scaling system for Demi's conductor. This tracks system resource usage, analyzes patterns with a 30-minute sliding window, uses ML models to predict future needs, and automatically scales integrations to stay within the 12GB RAM constraint.

Purpose: Proactively manage resources to prevent system overload while maintaining optimal performance.
Output: Working auto-scaling system with predictive ML models and graceful degradation.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@~/.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@src/core/config.py
@src/conductor/metrics.py
@src/plugins/manager.py
</context>

<tasks>

<task type="auto">
  <name>Implement resource monitoring system</name>
  <files>src/conductor/resource_monitor.py</files>
  <action>
    Create resource monitoring with historical tracking:
    - ResourceMonitor class with psutil integration
    - collect_metrics() gathering CPU, RAM, disk usage every 30 seconds
    - 30-minute sliding window storage (60 data points)
    - get_current_metrics() returning latest measurements
    - get_history() returning sliding window data
    - calculate_trends() for rate-of-change analysis
    - detect_anomalies() for sudden spikes
    - Integration with Prometheus metrics (system_resources gauge)
    - Async collection with proper error handling
    - Memory-efficient storage using deque with maxlen=60
    - Configurable collection interval via config system
  </action>
  <verify>python -c "
import asyncio
from src.conductor.resource_monitor import ResourceMonitor
async def test():
    rm = ResourceMonitor()
    metrics = await rm.collect_metrics()
    print(f'Current RAM: {metrics[\"memory\"]}%')
    print(f'History points: {len(rm.get_history())}')
asyncio.run(test())
"</verify>
  <done>Resource monitoring system tracks system metrics with 30-minute sliding window</done>
</task>

<task type="auto">
  <name>Build predictive auto-scaling engine</name>
  <files>src/conductor/scaler.py</files>
  <action>
    Create ML-based predictive scaling:
    - PredictiveScaler class with scikit-learn LinearRegression
    - update_model() training on last 50 resource data points
    - predict_load() forecasting resource needs 5 minutes ahead
    - Scaling thresholds: disable at 80% RAM, re-enable at 65% (hysteresis)
    - Graceful degradation order: Voice > Android > Discord > stubs
    - evaluate_and_adjust() main scaling decision method
    - Smoothing factors to prevent oscillation (exponential moving average)
    - Confidence intervals for predictions (fail-safe)
    - Integration with plugin manager for enable/disable actions
    - Scaling audit log with reasons and metrics
    - Configurable scaling parameters via config system
  </action>
  <verify>python -c "
import asyncio
from src.conductor.scaler import PredictiveScaler
from src.conductor.resource_monitor import ResourceMonitor
async def test():
    rm = ResourceMonitor()
    scaler = PredictiveScaler()
    # Mock some data
    for i in range(10):
        metrics = {'cpu': 50 + i, 'memory': 60 + i, 'disk': 40}
        rm.history.append(metrics)
    scaler.update_model(rm.get_history())
    prediction = scaler.predict_load({'cpu': 60, 'memory': 70, 'disk': 40})
    print(f'Predicted load: {prediction}%')
asyncio.run(test())
"</verify>
  <done>Predictive auto-scaling engine uses ML models to forecast and manage resources</done>
</task>

</tasks>

<verification>
Overall verification steps:
1. Verify resource monitoring collects accurate metrics
2. Test predictive model training with historical data
3. Validate scaling thresholds and hysteresis behavior
4. Test graceful degradation order with resource constraints
5. Verify oscillation prevention with smoothing factors
</verification>

<success_criteria>
- Resource monitor collects metrics every 30 seconds with sliding window
- Predictive scaler trains ML model on historical data
- Auto-scaling respects 80% disable / 65% enable thresholds
- Graceful degradation follows priority order correctly
- System prevents oscillation with smoothing and hysteresis
</success_criteria>

<output>
After completion, create `.planning/phases/02-conductor-orchestrator-integration-manager/02-03-SUMMARY.md`
</output>