---
phase: 08-voice-io
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified: ["src/integrations/discord_bot.py", "src/voice/voice_channel.py", "tests/test_discord_voice.py"]
autonomous: true

must_haves:
  truths:
    - "Discord bot joins voice channels when users connect"
    - "Voice input is transcribed and sent to LLM pipeline"
    - "LLM responses are spoken back in voice channels"
    - "Wake word 'Demi' triggers voice activation in always-listening mode"
    - "Voice responses have emotional tone modulation"
  artifacts:
    - path: "src/voice/voice_channel.py"
      provides: "Discord voice channel management"
      min_lines: 60
      contains: "class DiscordVoiceChannel"
    - path: "src/integrations/discord_bot.py"
      provides: "Updated Discord bot with voice support"
      min_lines: 100
      contains: "on_voice_state_update"
    - path: "tests/test_discord_voice.py"
      provides: "Discord voice integration tests"
      min_lines: 40
  key_links:
    - from: "src/voice/voice_channel.py"
      to: "src/voice/stt.py"
      via: "Voice audio transcription using WhisperSTT"
      pattern: "transcribe.*audio.*whisper"
    - from: "src/voice/voice_channel.py"
      to: "src/voice/tts.py"
      via: "LLM response to speech conversion using pyttsx3TTS"
      pattern: "speak.*text.*tts"
    - from: "src/integrations/discord_bot.py"
      to: "src/conductor/orchestrator.py"
      via: "Voice text routing through conductor inference pipeline"
      pattern: "request_inference.*voice"
    - from: "src/voice/voice_channel.py"
      to: "src/emotion/models.py"
      via: "Emotional state applied to TTS voice parameters"
      pattern: "emotional_state.*tone.*modulation"
---

<objective>
Integrate voice I/O system with Discord voice channels for real-time voice communication.

Purpose: Enable Demi to participate in Discord voice channels, listen to voice input, respond with speech output, and maintain always-listening mode with wake word detection.

Output: Discord bot with full voice channel support, wake word activation, and emotional voice responses.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@~/.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/08-voice-io/08-01-SUMMARY.md
@.planning/PROJECT.md
@.planning/ROADMAP.md
@src/integrations/discord_bot.py
@src/voice/stt.py
@src/voice/tts.py
@src/conductor/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Discord voice channel management system</name>
  <files>src/voice/voice_channel.py</files>
  <action>
1. Create DiscordVoiceChannel class in src/voice/voice_channel.py with:
   - join_voice_channel() and leave_voice_channel() methods
   - start_listening() for continuous audio capture
   - stop_listening() with proper cleanup
   - Audio buffer management and silence detection
   - Voice activity detection (VAD) to detect when user speaks
   - Wake word detection for "Demi" using simple audio pattern matching
   - Async audio processing pipeline

2. Implement audio processing:
   - 16kHz audio format compatibility with Whisper
   - Real-time audio chunking (1-second chunks)
   - Silence threshold to prevent false transcriptions
   - Audio quality optimization for speech recognition
   - Error handling for voice connection issues

3. Add configuration support:
   - Voice channel auto-join settings
   - Wake word sensitivity adjustment
   - Audio quality and buffer size configuration
   - Voice activity detection thresholds
  </action>
  <verify>python -c "from src.voice.voice_channel import DiscordVoiceChannel; print('Voice channel manager imports successfully')"</verify>
  <done>Discord voice channel management system created with audio processing capabilities</done>
</task>

<task type="auto">
  <name>Task 2: Update Discord bot with voice integration</name>
  <files>src/integrations/discord_bot.py</files>
  <action>
1. Update DiscordBot class with voice support:
   - Add voice intents to bot configuration
   - Implement on_voice_state_update() for voice channel monitoring
   - Add join_voice() and leave_voice() commands
   - Integrate voice channel manager with bot lifecycle
   - Handle voice connection permissions and errors

2. Add voice command handlers:
   - !join - Make bot join current voice channel
   - !leave - Make bot leave voice channel
   - !voice on/off - Enable/disable voice mode
   - !wake sensitivity - Adjust wake word sensitivity
   - Maintain backward compatibility with text commands

3. Integrate with conductor pipeline:
   - Route transcribed voice input through request_inference()
   - Send LLM responses to voice TTS system
   - Apply emotional state to voice responses
   - Handle voice mode configuration from user preferences
   - Log voice interactions for debugging

4. Voice state management:
   - Track active voice channels and user presence
   - Handle voice connection interruptions gracefully
   - Manage audio streams and cleanup on disconnect
   - Provide status indicators for voice mode
  </action>
  <verify>python -c "from src.integrations.discord_bot import DiscordBot; print('Discord bot with voice support imports successfully')"</verify>
  <done>Discord bot updated with full voice channel integration and command support</done>
</task>

<task type="auto">
  <name>Task 3: Implement wake word detection and emotional voice responses</name>
  <files>src/voice/voice_channel.py, tests/test_discord_voice.py</files>
  <action>
1. Implement wake word detection:
   - Simple keyword spotting for "Demi" using audio pattern matching
   - Configurable sensitivity and false positive filtering
   - Continuous audio monitoring in always-listening mode
   - Audio buffer management for wake word context
   - Performance optimization to minimize CPU usage

2. Add emotional voice response system:
   - Integrate EmotionalState from voice transcription results
   - Apply emotional tone modulation to TTS responses
   - Voice parameter mapping (rate, volume, pitch) by emotion:
     * Lonely: slower speech, softer volume
     * Excited: faster speech, energetic tone
     * Frustrated: quick pace, tense delivery
     * Confident: clear, steady speech
   - Smooth transitions between emotional states

3. Create comprehensive tests in tests/test_discord_voice.py:
   - Mock Discord voice client for unit tests
   - Test voice channel join/leave functionality
   - Test wake word detection accuracy
   - Test audio processing and silence detection
   - Test emotional voice response modulation
   - Test error handling and graceful fallbacks

4. Integration testing:
   - Test end-to-end voice flow: input -> STT -> LLM -> TTS -> output
   - Test concurrent voice and text interactions
   - Test voice mode toggle and configuration
   - Test performance under continuous audio processing
  </action>
  <verify>pytest tests/test_discord_voice.py -v && python -c "from src.voice.voice_channel import DiscordVoiceChannel; print('Voice channel with wake word detection ready')"</verify>
  <done>Wake word detection and emotional voice responses implemented with comprehensive test coverage</done>
</task>

</tasks>

<verification>
1. Discord bot can join and leave voice channels
2. Voice input is properly captured and transcribed
3. Wake word "Demi" triggers voice activation
4. LLM responses are spoken back with emotional modulation
5. Voice commands (!join, !leave, !voice) work correctly
6. Audio processing handles silence and background noise
7. Error handling works for voice connection issues
8. All tests pass for voice integration
</verification>

<success_criteria>
- Discord voice channel communication fully functional
- Wake word detection enables hands-free voice interaction
- Emotional voice responses match Demi's personality
- Robust error handling for voice connection issues
- Performance optimized for continuous audio processing
- Backward compatibility with existing text commands maintained
</success_criteria>

<output>
After completion, create `.planning/phases/08-voice-io/08-02-SUMMARY.md`
</output>