---
phase: 08-voice-io
plan: 03
type: execute
wave: 2
depends_on: [08-01, 08-02]
files_modified:
  - src/integrations/discord_voice.py
  - src/integrations/discord_bot.py
  - src/integrations/__init__.py
autonomous: true
user_setup:
  - service: discord
    why: "Discord voice channel integration for Demi"
    env_vars:
      - name: DISCORD_VOICE_ENABLED
        value: "true"
        source: "Set to 'true' to enable voice channel features"
      - name: DISCORD_WAKE_WORD
        value: "Demi"
        source: "Wake word to activate voice listening (default: 'Demi')"
      - name: DISCORD_VOICE_TIMEOUT_SEC
        value: "300"
        source: "Seconds of silence before leaving voice channel (default: 300)"
must_haves:
  truths:
    - "Discord bot connects to voice channels and handles voice I/O"
    - "Wake word 'Demi' activates listening mode"
    - "Always-listening in voice channels (with VAD)"
    - "Voice responses via TTS played to channel"
  artifacts:
    - path: "src/integrations/discord_voice.py"
      provides: "Discord voice client with STT/TTS pipeline"
      exports: ["DiscordVoiceClient", "VoiceSession"]
      min_lines: 250
  key_links:
    - from: "src/integrations/discord_voice.py"
      to: "src/voice/stt.py"
      via: "SpeechToText for voice input transcription"
      pattern: "stt\.transcribe_stream"
    - from: "src/integrations/discord_voice.py"
      to: "src/voice/tts.py"
      via: "TextToSpeech for response playback"
      pattern: "tts\.speak_response"
    - from: "src/integrations/discord_voice.py"
      to: "src/integrations/discord_bot.py"
      via: "shared bot instance and Conductor access"
      pattern: "discord_bot\.bot"
---

<objective>
Build Discord voice channel integration that enables Demi to join voice channels, listen for voice commands via wake word detection, process speech through the STTâ†’LLMâ†’TTS pipeline, and respond with synthesized voice. This creates a natural voice conversation experience in Discord.

Purpose: Complete VOICE-01, VOICE-02, VOICE-03, and VOICE-04 requirements by integrating the voice pipeline with Discord's voice infrastructure.

Output: DiscordVoiceClient with wake word detection, always-listening mode, and bidirectional voice I/O.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@.planning/REQUIREMENTS.md
@.planning/DISCORD_SETUP.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@DEMI_PERSONA.md
@src/integrations/discord_bot.py
@src/voice/stt.py
@src/voice/tts.py
@src/conductor/orchestrator.py
</context>

<tasks>

<task type="auto">
  <name>Create Discord voice client with connection management</name>
  <files>src/integrations/discord_voice.py</files>
  <action>Create `src/integrations/discord_voice.py` with DiscordVoiceClient:

**Imports:**
- `import discord`
- `from discord.ext import commands`
- `import asyncio`
- `import audioop`  # For audio conversion
- `import io`
- `from typing import Optional, Dict`
- `from datetime import datetime, timedelta`
- `from src.voice.stt import SpeechToText, TranscriptionResult`
- `from src.voice.tts import TextToSpeech`
- `from src.voice.vad import VoiceActivityDetector`
- `from src.core.logger import get_logger`

**Dataclass VoiceSession:**
```python
@dataclass
class VoiceSession:
    """Active voice session state."""
    voice_client: discord.VoiceClient
    channel_id: int
    guild_id: int
    start_time: datetime
    last_activity: datetime
    is_listening: bool = True
    is_speaking: bool = False
    wake_word_detected: bool = False
    pending_audio_buffer: bytes = b""
    user_speaking_start: Optional[datetime] = None
```

**Class DiscordVoiceClient:**
- `__init__(self, bot: commands.Bot, conductor)`:
  - Store bot reference
  - Store conductor for LLM access
  - Initialize STT: `self.stt = SpeechToText()`
  - Initialize TTS: `self.tts = TextToSpeech()`
  - Initialize VAD: `self.vad = VoiceActivityDetector()`
  - Setup logger
  - Track active sessions: `self.sessions: Dict[int, VoiceSession] = {}`
  - Configuration:
    - `self.wake_word = os.getenv("DISCORD_WAKE_WORD", "Demi")`
    - `self.voice_timeout_sec = int(os.getenv("DISCORD_VOICE_TIMEOUT_SEC", "300"))`
    - `self.listen_after_response = True  # Always-listening mode`
  
- `async def join_channel(self, channel: discord.VoiceChannel) -> bool`:
  - Connect to voice channel
  - Create VoiceSession
  - Start listening task
  - Return True on success
  
- `async def leave_channel(self, guild_id: int) -> bool`:
  - Disconnect from voice channel
  - Clean up session
  - Return True if was connected
  
- `async def leave_all_channels(self)`:
  - Disconnect from all voice channels (shutdown)
  
- `def is_connected_to(self, guild_id: int) -> bool`:
  - Check if connected to guild's voice channel
  
- `def get_session(self, guild_id: int) -> Optional[VoiceSession]`:
  - Return active session for guild

**Voice connection lifecycle:**
```python
async def _on_voice_connect(self, voice_client: discord.VoiceClient):
    """Called when successfully connected to voice channel."""
    self.logger.info(f"Connected to voice channel: {voice_client.channel.name}")
    
    # Play join sound (optional)
    await self._play_join_sound(voice_client)
    
    # Start listening loop
    asyncio.create_task(self._voice_listen_loop(voice_client))

async def _on_voice_disconnect(self, guild_id: int):
    """Called when disconnected from voice channel."""
    self.logger.info(f"Disconnected from voice channel in guild {guild_id}")
    
    if guild_id in self.sessions:
        del self.sessions[guild_id]
```

**Command handlers (to add to DiscordBot):**
- `!join` - Join user's current voice channel
- `!leave` - Leave voice channel
- `!voice on` - Enable always-listening
- `!voice off` - Disable listening (wake-word only)

**Implementation notes:**
- Use discord.py's VoiceClient for connection
- AudioSink for receiving audio
- FFmpegPCMAudio for playing audio
- Handle connection errors gracefully
- Log all voice state transitions
</action>
  <verify>
1. Import check: `python -c "from src.integrations.discord_voice import DiscordVoiceClient, VoiceSession; print('Discord voice import OK')"`
2. Class initialization:
   ```python
   from src.integrations.discord_voice import DiscordVoiceClient
   # Mock bot and conductor
   class MockBot:
       pass
   class MockConductor:
       pass
   
   dvc = DiscordVoiceClient(MockBot(), MockConductor())
   print(f"Wake word: {dvc.wake_word}")
   print(f"Timeout: {dvc.voice_timeout_sec}s")
   ```
3. Session management test:
   ```python
   # Test that sessions dict works
   assert dvc.sessions == {}
   print("Session management initialized")
   ```
  </verify>
  <done>DiscordVoiceClient created with connection management, session tracking, and configuration</done>
</task>

<task type="auto">
  <name>Implement wake word detection and audio receiving</name>
  <files>src/integrations/discord_voice.py</files>
  <action>Add wake word detection and audio receiving to DiscordVoiceClient:

**Audio receiving setup:**
```python
class DiscordAudioSink(discord.sinks.Sink):
    """Custom audio sink for Discord voice receiving."""
    
    def __init__(self, voice_client, callback):
        super().__init__()
        self.voice_client = voice_client
        self.callback = callback
        self.buffer = {}
        
    def write(self, data, user):
        """Called when audio packet received from user."""
        if user not in self.buffer:
            self.buffer[user] = io.BytesIO()
        self.buffer[user].write(data)
        
        # Call callback with audio data
        asyncio.create_task(self.callback(user, data))
        
    def cleanup(self):
        """Clear buffers."""
        self.buffer.clear()
```

**Wake word detection:**
```python
async def _voice_listen_loop(self, voice_client: discord.VoiceClient):
    """Main listening loop for voice channel."""
    session = self.sessions.get(voice_client.guild.id)
    if not session:
        return
    
    self.logger.info(f"Starting voice listen loop for guild {voice_client.guild.id}")
    
    while voice_client.is_connected() and session.is_listening:
        try:
            # Check for timeout
            if self._should_timeout(session):
                self.logger.info("Voice session timeout, leaving channel")
                await self.leave_channel(voice_client.guild.id)
                break
            
            # Receive audio (Discord sends 20ms Opus frames)
            # This is handled by the audio sink callback
            await asyncio.sleep(0.02)  # 20ms frame duration
            
        except Exception as e:
            self.logger.error(f"Voice listen loop error: {e}")
            await asyncio.sleep(1)

async def _on_audio_received(self, user_id: int, audio_data: bytes, session: VoiceSession):
    """Process received audio packet."""
    # Ignore bot's own audio
    if user_id == self.bot.user.id:
        return
    
    # Convert Discord Opus to PCM
    pcm_data = self._opus_to_pcm(audio_data)
    
    # Accumulate audio for VAD
    session.pending_audio_buffer += pcm_data
    
    # Check buffer size (keep last 5 seconds)
    max_buffer_size = 16000 * 2 * 5  # 16kHz, 16-bit, 5 seconds
    if len(session.pending_audio_buffer) > max_buffer_size:
        session.pending_audio_buffer = session.pending_audio_buffer[-max_buffer_size:]
    
    # Run VAD on latest frame
    is_speech = self._detect_speech(pcm_data)
    
    if is_speech:
        if not session.user_speaking_start:
            session.user_speaking_start = datetime.now()
        session.last_activity = datetime.now()
    else:
        # Speech ended - process buffer
        if session.user_speaking_start:
            duration = (datetime.now() - session.user_speaking_start).total_seconds()
            
            if duration > 0.5:  # Minimum 500ms for valid speech
                await self._process_utterance(session, user_id)
            
            session.user_speaking_start = None
            session.pending_audio_buffer = b""

async def _process_utterance(self, session: VoiceSession, user_id: int):
    """Process completed utterance through STT."""
    if len(session.pending_audio_buffer) < 1600:  # Min 50ms
        return
    
    # Transcribe audio
    transcription = await self.stt.transcribe_audio_buffer(session.pending_audio_buffer)
    
    if not transcription or not transcription.text:
        return
    
    self.logger.info(f"Transcribed: '{transcription.text}' from user {user_id}")
    
    # Check for wake word if not already active
    if not session.wake_word_detected:
        if self._check_wake_word(transcription.text):
            self.logger.info(f"Wake word detected from user {user_id}")
            session.wake_word_detected = True
            
            # Play acknowledgment sound
            await self._play_wake_acknowledgment(session.voice_client)
            
            # If only wake word spoken, wait for more
            if len(transcription.text.split()) <= 2:
                return
        else:
            # No wake word, ignore (unless always-listening mode)
            if not self.listen_after_response:
                return
    
    # Process through Conductor
    await self._process_voice_command(session, user_id, transcription.text)
    
    # Reset wake word detection for next interaction
    if not self.listen_after_response:
        session.wake_word_detected = False
```

**Wake word checking:**
```python
def _check_wake_word(self, text: str) -> bool:
    """Check if text contains wake word (case-insensitive)."""
    text_lower = text.lower().strip()
    wake_word_lower = self.wake_word.lower()
    
    # Exact match or beginning of sentence
    return (
        text_lower.startswith(wake_word_lower) or
        f" {wake_word_lower}" in text_lower
    )

def _should_timeout(self, session: VoiceSession) -> bool:
    """Check if voice session should timeout due to inactivity."""
    if not self.voice_timeout_sec:
        return False
    
    inactive_duration = (datetime.now() - session.last_activity).total_seconds()
    return inactive_duration > self.voice_timeout_sec
```

**Audio conversion:**
```python
def _opus_to_pcm(self, opus_data: bytes) -> bytes:
    """Convert Discord Opus audio to 16-bit PCM."""
    # Discord sends Opus at 48kHz stereo
    # We need 16kHz mono for Whisper
    
    # Use opuslib for decoding
    import opuslib
    
    decoder = opuslib.Decoder(48000, 2)  # 48kHz stereo
    pcm_stereo = decoder.decode(opus_data, 960)  # 20ms frame
    
    # Convert stereo to mono
    pcm_mono = audioop.tomono(pcm_stereo, 2, 0.5, 0.5)
    
    # Resample 48kHz â†’ 16kHz
    pcm_16k, _ = audioop.ratecv(pcm_mono, 2, 1, 48000, 16000, None)
    
    return pcm_16k

def _detect_speech(self, pcm_data: bytes) -> bool:
    """Run VAD on PCM audio."""
    # VAD expects 30ms frames at 16kHz = 480 samples = 960 bytes (16-bit)
    frame_duration_ms = 30
    frame_size = int(16000 * frame_duration_ms / 1000) * 2
    
    if len(pcm_data) < frame_size:
        return False
    
    # Take last frame
    frame = pcm_data[-frame_size:]
    
    return self.vad.is_speech(frame, 16000)
```

**Implementation notes:**
- Discord sends Opus-encoded audio at 48kHz stereo
- Must decode and resample to 16kHz mono for Whisper
- VAD runs continuously to detect speech boundaries
- Wake word detection resets after each command (unless always-listening)
- Buffer management prevents memory leaks
</action>
  <verify>
1. Wake word detection test:
   ```python
   from src.integrations.discord_voice import DiscordVoiceClient
   
   # Mock setup
   class MockBot:
       user = type('User', (), {'id': 123})()
   
   dvc = DiscordVoiceClient(MockBot(), None)
   
   # Test wake word detection
   assert dvc._check_wake_word("Demi, tell me something") == True
   assert dvc._check_wake_word("Hey Demi") == True
   assert dvc._check_wake_word("What time is it") == False
   assert dvc._check_wake_word("demi hello") == True  # Case insensitive
   print("Wake word detection working")
   ```
2. Timeout logic test:
   ```python
   from datetime import datetime, timedelta
   from src.integrations.discord_voice import VoiceSession
   
   # Create old session
   old_time = datetime.now() - timedelta(seconds=400)
   session = VoiceSession(
       voice_client=None,
       channel_id=1,
       guild_id=1,
       start_time=old_time,
       last_activity=old_time
   )
   
   assert dvc._should_timeout(session) == True
   
   # Create recent session
   session.last_activity = datetime.now()
   assert dvc._should_timeout(session) == False
   print("Timeout logic working")
   ```
3. Audio conversion test (mock opus data):
   ```python
   # Test with dummy data (opus decoder will fail but structure is tested)
   try:
       result = dvc._opus_to_pcm(b'dummy')
   except Exception as e:
       print(f"Audio conversion structure correct (expected error: {type(e).__name__})")
   ```
  </verify>
  <done>Wake word detection and audio receiving implemented with Opusâ†’PCM conversion, VAD integration, and session management</done>
</task>

<task type="auto">
  <name>Implement voice command processing and TTS response playback</name>
  <files>src/integrations/discord_voice.py</files>
  <action>Add voice command processing and TTS response to DiscordVoiceClient:

**Voice command processing:**
```python
async def _process_voice_command(
    self, 
    session: VoiceSession, 
    user_id: int, 
    text: str
):
    """Process transcribed voice command through LLM and respond."""
    
    self.logger.info(f"Processing voice command: '{text}'")
    
    # Get user info
    user = self.bot.get_user(user_id)
    user_name = str(user) if user else f"User_{user_id}"
    
    # Mark session as processing
    session.is_speaking = True
    
    try:
        # Build message for Conductor
        messages = [{
            "role": "user", 
            "content": f"[Voice] {user_name}: {text}"
        }]
        
        # Request inference from Conductor
        response = await self.conductor.request_inference(messages)
        
        # Extract response content
        if isinstance(response, dict):
            response_text = response.get("content", "")
            emotion_state = response.get("emotion_state", {})
        else:
            response_text = response
            emotion_state = {}
        
        self.logger.info(f"LLM response: '{response_text[:50]}...'")
        
        # Speak response via TTS
        await self._speak_in_channel(
            session.voice_client, 
            response_text, 
            emotion_state
        )
        
    except Exception as e:
        self.logger.error(f"Voice command processing error: {e}")
        # Play error message
        error_msg = "I'm sorry, I didn't catch that."
        await self._speak_in_channel(session.voice_client, error_msg, {})
    
    finally:
        session.is_speaking = False
        session.last_activity = datetime.now()
```

**TTS playback in Discord:**
```python
async def _speak_in_channel(
    self, 
    voice_client: discord.VoiceClient, 
    text: str,
    emotion_state: dict
):
    """Synthesize and play TTS audio in voice channel."""
    
    if not voice_client.is_connected():
        return
    
    # Wait if already playing
    while voice_client.is_playing():
        await asyncio.sleep(0.1)
    
    try:
        # Synthesize speech
        from src.models.emotional_state import EmotionalState
        
        emotion_obj = EmotionalState.from_dict(emotion_state) if emotion_state else None
        audio_path = await self.tts.speak(text, emotion_state=emotion_obj, save_path=None)
        
        if not audio_path or not os.path.exists(audio_path):
            self.logger.error("TTS synthesis failed")
            return
        
        # Play audio using FFmpeg
        audio_source = discord.FFmpegPCMAudio(audio_path)
        
        # Wrap with volume control (optional)
        audio_source = discord.PCMVolumeTransformer(audio_source, volume=1.0)
        
        # Play
        voice_client.play(audio_source, after=lambda e: self._on_playback_finished(e, audio_path))
        
        self.logger.info(f"Playing TTS response ({len(text)} chars)")
        
    except Exception as e:
        self.logger.error(f"TTS playback error: {e}")

def _on_playback_finished(self, error, audio_path: str):
    """Callback when audio playback completes."""
    if error:
        self.logger.error(f"Playback error: {error}")
    
    # Clean up temp file
    try:
        if os.path.exists(audio_path) and audio_path.startswith(tempfile.gettempdir()):
            os.remove(audio_path)
    except Exception as e:
        self.logger.warning(f"Failed to clean up audio file: {e}")
    
    self.logger.debug("TTS playback finished")

async def _play_join_sound(self, voice_client: discord.VoiceClient):
    """Play optional join sound when entering channel."""
    # Optional: play a subtle sound to indicate presence
    pass

async def _play_wake_acknowledgment(self, voice_client: discord.VoiceClient):
    """Play acknowledgment sound when wake word detected."""
    # Optional: play subtle "listening" sound
    pass
```

**Voice commands for DiscordBot:**
```python
# Add to src/integrations/discord_bot.py

@self.bot.command(name="join")
async def join_voice(ctx):
    """Join the user's current voice channel."""
    if not ctx.author.voice:
        await ctx.send("You need to be in a voice channel first, mortal.")
        return
    
    channel = ctx.author.voice.channel
    
    # Get voice client from DiscordBot
    if hasattr(self, 'voice_client') and self.voice_client:
        success = await self.voice_client.join_channel(channel)
        if success:
            await ctx.send(f"I have arrived. Speak 'Demi' to command me.", delete_after=10)
        else:
            await ctx.send("I cannot join that channel.")
    else:
        await ctx.send("Voice features are not available.")

@self.bot.command(name="leave")
async def leave_voice(ctx):
    """Leave the voice channel."""
    if hasattr(self, 'voice_client') and self.voice_client:
        success = await self.voice_client.leave_channel(ctx.guild.id)
        if success:
            await ctx.send("Leaving. Call me when you need divine wisdom.", delete_after=10)
        else:
            await ctx.send("I'm not in a voice channel.")

@self.bot.command(name="voice")
async def voice_control(ctx, action: str):
    """Control voice settings: !voice on | !voice off"""
    if not hasattr(self, 'voice_client') or not self.voice_client:
        await ctx.send("Voice features are not available.")
        return
    
    session = self.voice_client.get_session(ctx.guild.id)
    if not session:
        await ctx.send("I'm not in a voice channel.")
        return
    
    if action.lower() == "on":
        session.is_listening = True
        self.voice_client.listen_after_response = True
        await ctx.send("Always-listening mode enabled. I hear everything.", delete_after=10)
    
    elif action.lower() == "off":
        self.voice_client.listen_after_response = False
        await ctx.send("Wake-word only mode. Say 'Demi' to get my attention.", delete_after=10)
    
    else:
        await ctx.send("Usage: !voice on | !voice off")
```

**Implementation notes:**
- FFmpeg required for audio playback (must be installed on system)
- Use temp files for TTS audio (cleaned up after playback)
- Handle concurrent commands (don't interrupt ongoing speech)
- Log all voice interactions for debugging
- Support interruption (stop current speech on new command)
</action>
  <verify>
1. Command processing test:
   ```python
   # Verify method exists and structure is correct
   from src.integrations.discord_voice import DiscordVoiceClient
   import inspect
   
   assert hasattr(DiscordVoiceClient, '_process_voice_command')
   assert hasattr(DiscordVoiceClient, '_speak_in_channel')
   print("Voice command processing methods present")
   ```
2. Playback callback test:
   ```python
   import tempfile
   import os
   
   # Create temp file
   temp_file = tempfile.mktemp(suffix=".wav")
   with open(temp_file, 'w') as f:
       f.write("dummy")
   
   # Verify cleanup logic (mock)
   print(f"Temp file created: {temp_file}")
   assert os.path.exists(temp_file)
   os.remove(temp_file)
   print("Cleanup logic verified")
   ```
3. Integration with DiscordBot commands:
   ```python
   # Verify command decorators would work
   print("Commands defined: join, leave, voice")
   ```
  </verify>
  <done>Voice command processing and TTS playback implemented with FFmpeg integration and command handlers</done>
</task>

<task type="auto">
  <name>Integrate voice client with DiscordBot and Conductor</name>
  <files>src/integrations/discord_bot.py, src/integrations/discord_voice.py, src/integrations/__init__.py</files>
  <action>Integrate DiscordVoiceClient with existing DiscordBot:

**Update src/integrations/discord_bot.py:**

```python
# In DiscordBot.__init__, add:
def __init__(self):
    # ... existing initialization ...
    self.voice_client: Optional[DiscordVoiceClient] = None

# In DiscordBot.initialize, add:
async def initialize(self, conductor) -> bool:
    # ... existing initialization ...
    
    # Initialize voice client if enabled
    voice_enabled = os.getenv("DISCORD_VOICE_ENABLED", "false").lower() == "true"
    if voice_enabled:
        try:
            from src.integrations.discord_voice import DiscordVoiceClient
            self.voice_client = DiscordVoiceClient(self.bot, conductor)
            self.logger.info("Discord voice client initialized")
        except Exception as e:
            self.logger.error(f"Voice client initialization failed: {e}")
    
    # Register voice commands
    self._register_voice_commands()
    
    return True

def _register_voice_commands(self):
    """Register voice-related commands."""
    
    @self.bot.command(name="join")
    async def join_voice(ctx):
        if not self.voice_client:
            await ctx.reply("Voice features are disabled.", mention_author=False)
            return
        
        if not ctx.author.voice:
            await ctx.reply("Join a voice channel first, mortal.", mention_author=False)
            return
        
        success = await self.voice_client.join_channel(ctx.author.voice.channel)
        if success:
            embed = discord.Embed(
                title="ðŸ”® Voice Connected",
                description="I have arrived. Say 'Demi' to command me.",
                color=discord.Color.purple()
            )
            await ctx.reply(embed=embed, mention_author=False, delete_after=10)
        else:
            await ctx.reply("I cannot join that channel.", mention_author=False)
    
    @self.bot.command(name="leave")
    async def leave_voice(ctx):
        if not self.voice_client:
            await ctx.reply("Voice features are disabled.", mention_author=False)
            return
        
        success = await self.voice_client.leave_channel(ctx.guild.id)
        if success:
            embed = discord.Embed(
                title="ðŸ‘‹ Voice Disconnected",
                description="Call me when you need divine wisdom.",
                color=discord.Color.purple()
            )
            await ctx.reply(embed=embed, mention_author=False, delete_after=10)
        else:
            await ctx.reply("I'm not in a voice channel.", mention_author=False)

# In DiscordBot.shutdown, add:
async def shutdown(self) -> None:
    # ... existing shutdown ...
    
    # Shutdown voice client
    if self.voice_client:
        await self.voice_client.leave_all_channels()
        self.logger.info("Voice client shutdown")
```

**Update src/integrations/__init__.py:**
```python
# Add voice exports
from src.integrations.discord_voice import DiscordVoiceClient, VoiceSession

__all__ = [
    "DiscordBot",
    "DiscordVoiceClient",  # NEW
    "VoiceSession",        # NEW
]
```

**Update requirements.txt:**
```
# Voice I/O (Phase 08) - Discord Voice
discord.py[voice]>=2.6.0  # Includes voice support
opuslib>=3.0.1            # Opus codec for Discord
PyNaCl>=1.5.0             # Required for discord.py voice
```

**System requirements documentation:**
```markdown
## Discord Voice Setup

### Required System Packages

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install ffmpeg libopus0
```

**macOS:**
```bash
brew install ffmpeg opus
```

**Windows:**
- Download FFmpeg from https://ffmpeg.org/download.html
- Add to PATH environment variable

### Environment Variables

```bash
# Enable voice features
export DISCORD_VOICE_ENABLED=true

# Wake word (default: "Demi")
export DISCORD_WAKE_WORD="Demi"

# Voice timeout in seconds (default: 300)
export DISCORD_VOICE_TIMEOUT_SEC=300
```

### Voice Commands

- `!join` - Join your current voice channel
- `!leave` - Leave voice channel
- `!voice on` - Enable always-listening mode
- `!voice off` - Wake-word only mode
```

**Implementation notes:**
- Voice features require FFmpeg installed on system
- Discord voice uses Opus codec (opuslib package)
- PyNaCl required for discord.py voice encryption
- Voice client is optional (system works without it if disabled)
</action>
  <verify>
1. DiscordBot integration test:
   ```python
   # Verify voice_client attribute exists
   from src.integrations.discord_bot import DiscordBot
   import inspect
   
   # Check that voice_client is initialized in __init__
   source = inspect.getsource(DiscordBot.__init__)
   assert 'voice_client' in source
   print("DiscordBot has voice_client integration")
   ```
2. Command registration test:
   ```python
   # Verify commands are defined
   source = inspect.getsource(DiscordBot._register_voice_commands)
   assert 'join_voice' in source
   assert 'leave_voice' in source
   print("Voice commands registered")
   ```
3. Exports check:
   ```python
   from src.integrations import DiscordVoiceClient, VoiceSession
   print("Voice exports working")
   ```
4. Requirements check: Verify discord.py[voice], opuslib, PyNaCl in requirements.txt
  </verify>
  <done>DiscordVoiceClient integrated with DiscordBot, voice commands registered, exports updated, system requirements documented</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Voice Connection:** Use `!join` in Discord â†’ bot joins voice channel
2. **Wake Word Detection:** Say "Demi" in voice channel â†’ bot acknowledges
3. **STT Pipeline:** Say "Demi, what time is it" â†’ transcription logged
4. **LLM Response:** Command processed â†’ response text generated
5. **TTS Playback:** Response spoken in voice channel
6. **Leave Command:** Use `!leave` â†’ bot leaves channel
7. **Always-Listening:** Enable with `!voice on` â†’ responds without wake word

**End-to-end test:**
1. User joins voice channel
2. User types `!join`
3. User says "Demi, hello"
4. Bot transcribes, processes through LLM, speaks response
5. User says "tell me a joke" (no wake word in always-listening mode)
6. Bot responds with joke
7. Silence for 5 minutes â†’ bot auto-leaves

**Benchmark targets:**
- Join latency: <3s
- Wake word response: <1s acknowledgment
- Full pipeline (STTâ†’LLMâ†’TTS): <10s end-to-end
- Audio quality: Clear, intelligible speech
</verification>

<success_criteria>
- DiscordVoiceClient connects to voice channels via `!join` command
- Wake word "Demi" detected in voice audio
- Voice commands transcribed via STT
- LLM responses generated and spoken via TTS
- `!leave` command disconnects from channel
- Always-listening mode toggles with `!voice on/off`
- Voice timeout after configured period of inactivity
- Voice client integrates with existing DiscordBot
- Voice features can be disabled via environment variable
- FFmpeg and Opus dependencies documented
- Test coverage >75% for voice integration
</success_criteria>

<output>
After completion, create `.planning/phases/08-voice-io/08-03-SUMMARY.md`
</output>
